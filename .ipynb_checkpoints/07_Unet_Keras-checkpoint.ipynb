{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET을 이용한 컬러 복원 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WITHJS\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import UpSampling2D, BatchNormalization, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 클래스 선언 및 초기화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ic 는 이미지 행렬에서 어떤 차원에 채널 수가 기록되었는지 저장\n",
    "* keras는 고차원 라이브러리이다. \n",
    "* keras는 실행하는 기본 엔진을 Tensorflow, Theano, CNTK 를 사용한다.\n",
    "* 기본값은 다음의 값을 갖는다.\n",
    "```\n",
    "{\n",
    "    \"image_data_format\": \"channels_last\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"tensorflow\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (QA) channels_last, channels_first의 차이는 무엇일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "1e-07\n",
      "float32\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "print( backend.image_data_format() ) # channels_last, channels_first 존재\n",
    "print( backend.epsilon() )\n",
    "print( backend.floatx() )\n",
    "print( backend.backend() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (QA) ic = 3 과 ic = 1의 차이는?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv \n",
    " * LeNet 필터 이용 (5,5)\n",
    " * AlexNet 필터 이용 (11,11), (7,7), (3,3)\n",
    " * VGG, ResNet, Xception 필터 이용 (3,3)\n",
    " * 배치 정규화와 드롭아웃 계층은 어떻게 하는가에 따라 신경망을 구성하는 형태와 입력 데이터의 종류에 따라 달라짐. 최적의 조합은 경험을 통해 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (QA) ic = 3 과 ic = 1의 차이는?\n",
    "class UNET(models.Model):   # models.Model을 상속받음.\n",
    "    def __init__(self, org_shape, n_ch):\n",
    "        # ic = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "        if backend.image_data_format() == 'channels_last':\n",
    "            ic = 3\n",
    "        else:\n",
    "            ic = 1\n",
    "            \n",
    "        # UNET 용 합성곱 계층 블록\n",
    "        # MaxPooling 정의\n",
    "        # 활성함수 및 Dropout 정의\n",
    "        def conv(x, n_f, mp_flag=True):\n",
    "            # 입력 이미지를 (2,2) 단위의 작은 이미지로 나누고 가장 큰 값을 출력\n",
    "            # mp_flag가 True일때만 동작\n",
    "            x = MaxPooling2D( (2,2), padding='same')(x) if mp_flag else x # 1/4로 줄게됨.\n",
    "            \n",
    "            # Conv2D 합성곱 필터(3,3), 개수 n_f로 지정\n",
    "            # 활성화 함수 : tanh 로 설정\n",
    "            # 초기에는 (5,5), (7,7), (11,11)사용했으나, 이후 (3,3)이 성능이 좋아, \n",
    "            # 보편적으로 (3,3) 사용됨.\n",
    "            x = Conv2D(n_f, (3,3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            x = Dropout(0.05)(x)  # 과적합되지 않도록 정규화와 드롭 확률을 5%로 함.\n",
    "            \n",
    "            x = Conv2D(n_f, (3,3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            return x\n",
    "        \n",
    "        # 역합성곱 계층 블록\n",
    "        def deconv_unet(x, e, n_f):\n",
    "            # 들어온 이미지를 지정된 배수만큼 늘린다.\n",
    "            x = UpSampling2D((2,2))(x)   # 좌우 두배씩 늘리기 \n",
    "            x = Concatenate(axis=ic)([x,e])  # 두 입력을 결합, 합쳐지는 차원은 ic로 결정. ic는 이미지 채널의 차원\n",
    "            \n",
    "            # 첫 번째 합성곱, 드롭아웃이 없다.\n",
    "            # 이미지 확장단계에서 Dropout이 잘 사용되지 않는 경향이 있다.\n",
    "            x = Conv2D(n_f, (3,3), padding='same')(x) # 역합성곱 계산\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            \n",
    "            # 두 번째 합성곱\n",
    "            x = Conv2D(n_f, (3,3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('tanh')(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        # Input(입력)\n",
    "        original = Input(shape=org_shape)\n",
    "        \n",
    "        #################################\n",
    "        # Encoding(부호화)\n",
    "        # 각 계층에 사용된 필터 수 16개, 32개, 64개\n",
    "        # 반복 횟수, 단계별 사용 필터 수는 하이퍼 파리미터이다.\n",
    "        # 이미지 데이터는 c1, c2, c3에 저장됨.\n",
    "        c1 = conv(original, 16, mp_flag=False) # 이미지가 줄지 않았다. mp_flag=True만 동작\n",
    "        c2 = conv(c1, 32)                      # 1/4로 줄어듬\n",
    "        \n",
    "        # Encoder \n",
    "        encoded = conv(c2, 64)                 # 1/4로 줄어듬\n",
    "        #################################\n",
    "        \n",
    "        ## ==========================\n",
    "        ## 복호화 단계\n",
    "        x = deconv_unet(encoded, c2, 32)     # deconv_unet 호출\n",
    "        x = deconv_unet(x, c1, 16)           # deconv_unet 호출 - 역합성곱\n",
    "        \n",
    "        decoded = Conv2D(n_ch, (3,3), activation='sigmoid', padding='same')(x)\n",
    "        ## ==========================\n",
    "        \n",
    "        super().__init__(original, decoded)  # 부모 클래스의 초기화 함수 호출\n",
    "        self.compile(optimizer='adadelta', loss='mse')  #  최적화 함수 : Adadelta(), 출력입력오차비교 : mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 데이터 준비 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용할 데이터 셋 : CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) 4\n"
     ]
    }
   ],
   "source": [
    "## 확인\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "print( x_train.shape, x_train.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA():\n",
    "    def __init__(self, in_ch=None):\n",
    "        (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "        \n",
    "        if x_train.ndim == 4:  # 4이면 컬러 이미지 \n",
    "            # n_ch : 채널 수, img_rows: 행 크기, img_cols: 열 크기 \n",
    "            if backend.image_data_format() == 'channels_first':\n",
    "                n_ch, img_rows, img_cols = x_train.shape[1:]  \n",
    "            else:\n",
    "                img_rows, img_cols, n_ch = x_train.shape[1:]  \n",
    "        else:  # 흑백 이미지 처리\n",
    "            img_rows, img_cols = x_train.shape[1:]\n",
    "            n_ch = 1\n",
    "        \n",
    "        in_ch = n_ch if in_ch is None else in_ch  # in_ch가 빈값이면 n_ch, 아니면 in_ch로 넣기\n",
    "        \n",
    "        # 인공신경망에 적합한 0~1 사이의 실수로 변환\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        \n",
    "        x_train /= 255\n",
    "        x_test /=255\n",
    "        \n",
    "        ## 컬러를 흑백으로 만드는 함수 정의 \n",
    "        def RGB2Gray(X, fmt):\n",
    "            if fmt == 'channels_first':\n",
    "                R = X[:, 0:1]\n",
    "                G = X[:, 1:2]\n",
    "                B = X[:, 2:3]\n",
    "            else:    # 'channels_last'\n",
    "                R = X[..., 0:1]\n",
    "                G = X[..., 1:2]\n",
    "                B = X[..., 2:3]\n",
    "            return 0.299 * R + 0.587 * G + 0.114 * B  # 컬러 이미지를 흑백으로 변경\n",
    "        \n",
    "        def RGB2RG(x_train_out, x_test_out, fmt):\n",
    "            if fmt=='channels_first':\n",
    "                x_train_in = x_train_out[: , 0:2]\n",
    "                x_test_in = x_test_out[:, 0:2]\n",
    "            else:\n",
    "                x_train_in = x_train_out[...,0:2]\n",
    "                x_test_in = x_test_out[..., 0:2]\n",
    "            return x_train_in, x_test_in\n",
    "        \n",
    "        ## 흑백이미지의 차원을 3차원에서 4차원으로 변경\n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], n_ch, img_rows, img_cols)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], n_ch, img_rows, img_cols)\n",
    "            input_shape = (in_ch, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train_out = x_train.reshape(x_train.shape[0], img_rows, img_cols, n_ch)\n",
    "            x_test_out = x_test.reshape(x_test.shape[0], img_rows, img_cols, n_ch)\n",
    "            input_shape = (img_rows, img_cols, in_ch)\n",
    "                \n",
    "        ## RGB2Gray() 함수 데이터에 적용\n",
    "        if in_ch ==1 and in_ch==3:\n",
    "            x_train_in = RGB2Gray(x_train_out, backend.image_data_format())\n",
    "            x_test_in = RGB2Gray(x_test_out, backend.image_data_format())\n",
    "        elif in_ch == 2 and n_ch == 3:\n",
    "            x_train_in, x_test_in = RGB2RG(x_train_out, x_test_out, \n",
    "                                          backend.image_data_format())\n",
    "        else:\n",
    "            x_train_in = x_train_out\n",
    "            x_test_in = x_test_out\n",
    "            \n",
    "        self.input_shape = input_shape\n",
    "        self.x_train_in, self.x_train_out = x_train_in, x_train_out\n",
    "        self.x_test_in, self.x_test_out = x_test_in, x_test_out\n",
    "        self.n_ch = n_ch\n",
    "        self.in_ch = in_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. UNET 처리 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# UNET 검증\n",
    "###########################\n",
    "from keraspp.skeras import plot_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# UNET 동작 확인\n",
    "###########################\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "\n",
    "def show_images(data, unet):\n",
    "    x_test_in = data.x_test_in\n",
    "    x_test_out = data.x_test_out\n",
    "    decoded_imgs_org = unet.predict(x_test_in)\n",
    "    decoded_imgs = decoded_imgs_org\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        print(x_test_out.shape)\n",
    "        x_test_out = x_test_out.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        print(x_test_out.shape)\n",
    "        decoded_imgs = decoded_imgs.swapaxes(1, 3).swapaxes(1, 2)\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[:, 0, ...]\n",
    "        elif data.in_ch == 2:\n",
    "            print(x_test_out.shape)\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "        else:\n",
    "            x_test_in = x_test_in.swapaxes(1, 3).swapaxes(1, 2)\n",
    "    else:\n",
    "        # x_test_in = x_test_in[..., 0]\n",
    "        if data.in_ch == 1:\n",
    "            x_test_in = x_test_in[..., 0]\n",
    "        elif data.in_ch == 2:\n",
    "            x_test_in_tmp = np.zeros_like(x_test_out)\n",
    "            x_test_in_tmp[..., :2] = x_test_in\n",
    "            x_test_in = x_test_in_tmp\n",
    "\n",
    "    n = 10\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1)\n",
    "        if x_test_in.ndim < 4:\n",
    "            plt.imshow(x_test_in[i], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(x_test_in[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n * 2)\n",
    "        plt.imshow(x_test_out[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(in_ch=1, epochs=10, batch_size=512, fig=True):\n",
    "    ###########################\n",
    "    # 학습 및 확인\n",
    "    ###########################\n",
    "\n",
    "    data = DATA(in_ch=in_ch)\n",
    "    print(data.input_shape, data.x_train_in.shape)\n",
    "    unet = UNET(data.input_shape, data.n_ch)\n",
    "\n",
    "    history = unet.fit(data.x_train_in, data.x_train_out,\n",
    "                       epochs=epochs,\n",
    "                       batch_size=batch_size,\n",
    "                       shuffle=True,\n",
    "                       validation_split=0.2)\n",
    "\n",
    "    if fig:\n",
    "        plot_loss(history)\n",
    "        show_images(data, unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input_channels INPUT_CHANNELS]\n",
      "                             [--epochs EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                             [--fig FIG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\WITHJS\\AppData\\Roaming\\jupyter\\runtime\\kernel-7e1ba0e2-1708-47fd-8714-dafd5d66ea1c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WITHJS\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "__name__ = '__main__'\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    from distutils import util\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='UNET for Cifar-10: Gray to RGB')\n",
    "    parser.add_argument('--input_channels', type=int, default=1,\n",
    "                        help='input channels (default: 1)')\n",
    "    parser.add_argument('--epochs', type=int, default=10,\n",
    "                        help='training epochs (default: 10)')\n",
    "    parser.add_argument('--batch_size', type=int, default=512,\n",
    "                        help='batch size (default: 1000)')\n",
    "    parser.add_argument('--fig', type=lambda x: bool(util.strtobool(x)),\n",
    "                        default=True, help='flag to show figures (default: True)')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Aargs:\", args)\n",
    "\n",
    "    print(args.fig)\n",
    "    main(args.input_channels, args.epochs, args.batch_size, args.fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
