{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### colab로 시작하기\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/LDJWJ/AISTUDY/blob/master/DL05_01_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 이해하기\n",
    " * RNN이라는 무엇일까?\n",
    " * RNN의 활용 예\n",
    " * RNN는 무엇의 약자일까?\n",
    " * 신경망과 무엇이 다른가?\n",
    " * MNIST 어떻게 구현할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN의 활용\n",
    " * 2016 년의 기계 번역"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN의 용어 이해\n",
    " * 순환 신경망(Recurrent Neural Network)이다.\n",
    " * RNN은 상태가 고정된 데이터를 처리하는 다른 신경망과 달리 자연어 처리나 음성 인식처럼 **순서가 있는 데이터를 처리하는 데 강점**이 있다.\n",
    " * 앞이나 뒤의 정보에 따라 전체의 의미가 달라질 때,\n",
    " * **앞의 정보로 다음에 나오는 정보를 추측**하려고 할 때, RNN을 사용하면 좋은 프로그램을 만들 수 있다.\n",
    " * 2016년 구글의 신경망 기반 기계 번역이 RNN을 이용하여 만든 서비스이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN의 구조 이해\n",
    " * RNN은 셀을 여러개 중첩하여 심층 신경망을 만든다.\n",
    " * 앞의 학습 결과를 다음 단계의 학습에 이용한다. \n",
    " * 학습 데이터를 단계별로 구분하여 입력을 한다.\n",
    " * MNIST를 RNN에 적용한다고 하면, 한 줄단위(28픽셀)을 한 단계의 입력값으로 한다. 총 28단계를 거쳐 입력받음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/Rnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 하이퍼 파라미터 변수 지정 : 학습률(learning_rate), 총 에폭(epochs), 배치 사이즈(batch_size)\n",
    "######\n",
    "learning_rate = 0.001\n",
    "total_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "# RNN 은 순서(시퀀스)가 있는 자료를 다루므로,\n",
    "# 한 번에 입력받는 갯수와, 총 몇 단계로 이루어져있는 데이터를 받을지를 설정해야합니다.\n",
    "# 이를 위해 가로 픽셀수를 n_input 으로, 세로 픽셀수를 입력 단계인 n_step 으로 설정하였습니다.\n",
    "n_input = 28   # 입력\n",
    "n_step = 28    # 28단계 ( 28 X 28)\n",
    "n_hidden = 128 # 은닉층 노드 수 : 128\n",
    "n_class = 10   # 클래스 : 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 모델 구성\n",
    "* RNN은 **순서가 있는 데이터**를 다룬다. \n",
    "* 한번에 입력받을 데이터 개수와 총 몇 단계로 이뤄진 데이터를 받을 지 설정(n_step)해야 함.\n",
    "* 기존과 다른 점 - n_step의 차원이 하나 더 추가됨.\n",
    "  ```\n",
    "  X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "  ```\n",
    "* 이미지의 경우, 가로 픽셀 수(n_input), 세로 픽셀 수(n_step)으로 설정\n",
    "* 출력값은 기존의 신경망과 동일하게 원핫 인코딩으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor X:  Tensor(\"Placeholder_2:0\", shape=(?, 28, 28), dtype=float32)\n",
      "tensor Y:  Tensor(\"Placeholder_3:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])  # n_step 차원을 추가\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "print(\"tensor X: \", X)\n",
    "print(\"tensor Y: \", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow에서 함수 제공하여 간단하게 RNN 셀 생성\n",
    " * RNN의 기본 신경망은 다양한 방식의 셀을 사용할 수 있는 함수를 제공\n",
    " * RNN의 기본 신경망은 단점이 있음. \n",
    "    * 긴 단계의 데이터를 학습할 때 맨 뒤에서는 맨 앞의 정보를 잘 기억하지 못함.\n",
    "    * 단점을 어느정도 보완하여 많이 사용하는 것이 LSTM(Long Short-Term Memory)의 신경망\n",
    " * GRU(Gated Recurrent Units) 신경망 : LSTM과 비슷하지만 구조가 더 간단한 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 구성을 위한 셀을 구성\n",
    " * 하나의 셀(RNN)이 n_hidden 개의 출력값을 갖는 셀을 생성\n",
    " * BasicRNNCell : 기본 RNN셀\n",
    " * 기타 : BasicLSTMCell,GRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-04e2e91f69aa>:1: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "<tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x00000215C9B59F60>\n"
     ]
    }
   ],
   "source": [
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "print(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 완성\n",
    " * dynamic_rnn : cell을 이용하여 RNN 신경망을 만든다.\n",
    "   * dynamic_rnn의 함수는 자동적으로 RNN 구조의 신경망의 처리를 구현해 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 신경망의 반복 과정 \n",
    "```\n",
    "states = tf.zeros(batch_size)\n",
    "for i in range(n_step):\n",
    "    outputs, states = cell(X[[:, i]], states)\n",
    "...\n",
    "다음처럼 tf.nn.dynamic_rnn 함수를 사용하면\n",
    "CNN 의 tf.nn.conv2d 함수처럼 간단하게 RNN 신경망을 만들어줍니다.\n",
    "```\n",
    "* 한 단계를 학습한 뒤, 상태를 저장한다. \n",
    "* 그 상태를 다음 단계의 입력 상태로 하여 다시 학습한다.\n",
    "* 주어진 단계만큼 반복하면서 상태를 전파하며 출력값을 만들어간다. RNN의 기본 구조\n",
    "* 이에 대한 전 단계를 고려하며 RNN의 모델의 핵심 구조를 만들 수 있는 것이 dynamic_rnn함수이다.\n",
    "  * dynamic_rnn : https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn_1/transpose_1:0\", shape=(?, 28, 128), dtype=float32)\n",
      "Tensor(\"rnn_1/while/Exit_3:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "print(outputs)  # 전체 cell별 출력\n",
    "print(states)   # The final state(마지막 단계의 상태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(128, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# 각 셀의 결과값에 대한 weight 변수\n",
    "W_out = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b_out = tf.Variable(tf.random_normal([n_class]))\n",
    "print(W_out)\n",
    "print(b_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 모델 만들기\n",
    "* RNN 신경망이 출력값의 형태 -> [batch_size, n_step, n_hidden]\n",
    "  * batch_size : 데이터의 개수\n",
    "  * n_step : RNN의 단계\n",
    "  * n_hidden : 은닉층의 노드 수\n",
    "  \n",
    "* 우리는 위의 형태를 최종 결과값인 (?, output_unit)에 맞추기 위해\n",
    "* 행렬 곱을 위해 얻어진 output의 차원의 순서를 변경해 준다.\n",
    "  * (가) 순서 바꾸기 :  [batch_size, n_step, n_hidden]  -> [n_step, batch_size, n_hidden]\n",
    "  * (나) n_step의 차원을 제거 [batch_size, n_hidden]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과를 Y의 (?(배치사이즈), 10)의 최종결과를 얻기 위해\n",
    " * Y : [batch_size, n_class]\n",
    " * outputs 의 배열의 shape를 이에 맞춰 변경해야합니다.\n",
    "\n",
    "### 초기 \n",
    " * outputs : [batch_size, n_step(작업 단계), n_hidden] \n",
    " * 변경 -> [n_step, batch_size, n_hidden]\n",
    "\n",
    "### 사용 함수\n",
    " * tf.transpose 함수를 이용하여 n_step과 batch_size의 차원의 순서를 바꾸고, \n",
    " * n_step 차원을 제거하여 마지막 단계의 결과값을 취함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn_1/transpose_1:0\", shape=(?, 28, 128), dtype=float32)\n",
      "Tensor(\"transpose:0\", shape=(28, ?, 128), dtype=float32)\n",
      "Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "\n",
    "# 순서 바꾸기 [batch_size, n_step, n_hidden] -> [n_step, batch_size, n_hidden]\n",
    "outputs1 = tf.transpose(outputs, [1, 0, 2])   \n",
    "print(outputs1)\n",
    "\n",
    "#  -> [batch_size, n_hidden]\n",
    "outputs2 = outputs1[-1]   # 최종 마지막의 결과값(output)만 취한다.\n",
    "print(outputs2)\n",
    "\n",
    "# 최종 결과값를 활용하여 model 완성\n",
    "model = tf.matmul(outputs2, W_out) + b_out   # ( ?, 128 ) * (128, 10) => ?, 10 \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost(비용), optimizer(최적화 알고리즘) 지정\n",
    "* 손실(Loss) 함수 : cross_entropy\n",
    "* 최적화 알고리즘 : AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))  # 10개 분류 모델\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터\n",
    " * total_epoch : 30\n",
    " * batch_size : 128\n",
    " * n_step : 28\n",
    " * n_input : 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * batch_xs 데이터 형태를 신경망에 맞춰 형 변환\n",
    " * [batch_size, n_step, n_input]\n",
    "    * batch_xs = batch_xs.reshape((batch_size, n_step, n_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.603\n",
      "Epoch: 0002 Avg. cost = 0.263\n",
      "Epoch: 0003 Avg. cost = 0.194\n",
      "Epoch: 0004 Avg. cost = 0.167\n",
      "Epoch: 0005 Avg. cost = 0.149\n",
      "Epoch: 0006 Avg. cost = 0.128\n",
      "Epoch: 0007 Avg. cost = 0.121\n",
      "Epoch: 0008 Avg. cost = 0.118\n",
      "Epoch: 0009 Avg. cost = 0.110\n",
      "Epoch: 0010 Avg. cost = 0.106\n",
      "Epoch: 0011 Avg. cost = 0.099\n",
      "Epoch: 0012 Avg. cost = 0.090\n",
      "Epoch: 0013 Avg. cost = 0.092\n",
      "Epoch: 0014 Avg. cost = 0.086\n",
      "Epoch: 0015 Avg. cost = 0.083\n",
      "Epoch: 0016 Avg. cost = 0.075\n",
      "Epoch: 0017 Avg. cost = 0.083\n",
      "Epoch: 0018 Avg. cost = 0.073\n",
      "Epoch: 0019 Avg. cost = 0.077\n",
      "Epoch: 0020 Avg. cost = 0.071\n",
      "Epoch: 0021 Avg. cost = 0.077\n",
      "Epoch: 0022 Avg. cost = 0.065\n",
      "Epoch: 0023 Avg. cost = 0.070\n",
      "Epoch: 0024 Avg. cost = 0.066\n",
      "Epoch: 0025 Avg. cost = 0.065\n",
      "Epoch: 0026 Avg. cost = 0.070\n",
      "Epoch: 0027 Avg. cost = 0.066\n",
      "Epoch: 0028 Avg. cost = 0.063\n",
      "Epoch: 0029 Avg. cost = 0.063\n",
      "Epoch: 0030 Avg. cost = 0.059\n",
      "최적화 완료!\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # print(\"변경 전 : \", batch_xs.shape)  # batch_xs : 128, 784\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))  # 신경망에 맞춰 데이터 변환 \n",
    "        # print(\"변경 후 : \", batch_xs.shape)  # batch_xs : 128, 28, 28\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인\n",
    " * 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(is_correct)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 준비 \n",
    " * reshape 를 하여 변경\n",
    " * test_batch_size : 10000, n_step : 28, n_input : 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test_batch_size)  # 전체 데이터 개수\n",
    "print(test_xs.shape)\n",
    "print(test_ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9734\n"
     ]
    }
   ],
   "source": [
    "print('정확도:', sess.run(accuracy,\n",
    "                       feed_dict={X: test_xs, Y: test_ys}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFERENCE \n",
    " * 골빈 해커의 3분 딥러닝 책 참조\n",
    " * dynamic_rnn 함수 :  https://www.tensorflow.org/api_docs/python/tf/compat/v1/nn/dynamic_rnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
