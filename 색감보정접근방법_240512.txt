
위성 사진.
===================
저는 자동으로 위성 영상의 색감을 일관되게 보정할 방법을 모색하고 있습니다. 

구현하고자 하는 모델은 자동으로 경계선을 인식하고, 히스토그램 매칭 또는 기계학습/심층학습을 기반으로 색상을 일관성 있게 조정할 수 있는 기능을 갖춘 모델을 구성해보고 싶습니다.

이 주제를 연구 과제로 설정하고 진행해보고자 하는데, 
이 문제해결에 접근하는 데 있어 어떤 방법이 좋을지 어떻게 접근하면 좋을지
====================
[딥러닝 접근법]
01. 영역 분할(Semantic Segmentation) 모델 활용
 - 영역 분할 모델을 활용하여 위성영상에서 지형지물을 자동으로 인식하고 분류. (예: 건물, 도로, 식생, 수역 )
 - 각 클래스별로 목표 색상 값을 설정하고, 이를 기준으로 해당 영역의 색상을 조정.

02. 생성적 적대 신경망(GAN) 모델 활용
 - 색상이 일관된 참조 데이터셋과 보정이 필요한 위성영상 데이터셋을 준비
 - GAN 모델을 통해 참조 데이터셋의 스타일을 위성영상에 전이시켜 색상을 보정

03. 딥러닝 기반 이미지 대 이미지 변환(Image-to-Image Translation) 모델 활용
 - 마찬가지로 두 개의 데이터셋(입력 위성영상, 목표 출력 영상)을 준비
 - 이미지 변환 모델을 학습시켜 입력 위성영상의 색상을 목표 출력 영상의 스타일로 변환

기타 전통적 컴퓨터 비전 
히스토그램 매칭, 컬러 트랜스퍼 등 방법 



01. 히스토그램 매칭 및 색상 보정
 - 히스토그램 매칭: 특정 이미지의 히스토그램을 기준으로 대상 이미지의 히스토그램을 일치시키는 방법
 - 화이트 밸런스 및 색상 보정: 각 이미지에서 화이트 밸런스를 보정하거나 특정 색상 채널을 조절하는 방법입니다. OpenCV나 scikit-image 등의 라이브러리를 활용해 화이트 밸런스를 개선

02. 이미지 세그멘테이션 및 경계선 인식
 - 이미지 세그멘테이션: 경계선을 인식하기 위해 딥러닝 기반의 이미지 세그멘테이션 기법을 활용할 수 있습니다. U-Net, Mask R-CNN과 같은 모델
 - 경계선 인식: 세그멘테이션으로 추출한 경계선을 통해 각 영역의 색상을 따로 보정하는 방법

03. 머신러닝 및 딥러닝 모델 활용
 - Transfer Learning: 사전 학습된 모델을 활용하여 경계선 인식 또는 색상 조정 모델을 빠르게 학습
 - CNN 기반 모델: 딥러닝을 활용해 이미지 간 색상 일관성을 학습하는 방법입니다. GAN(Generative Adversarial Network) 기반 모델

04. 

===========
안녕하세요. 실무자들의 의견을 구하고 싶다는 취지를 잘 이해했습니다. 위성영상 처리 분야에서 색상 보정은 매우 중요한 문제이며, 아직까지 완벽한 해결책은 없는 상황입니다. 실무에서 어떤 방식을 주로 사용하는지, 그리고 새로운 접근법에 대한 의견을 말씀드리겠습니다.

1. 전통적인 방법으로는 히스토그램 매칭, 컬러 트랜스퍼, 파나로믹 색상 보정 등을 주로 사용합니다. 이런 방식들은 계산 비용이 적고 구현이 쉬운 장점이 있지만, 완벽한 색상 일치를 보장하기 어렵습니다.

2. 최근에는 딥러닝 기반 방법들이 활발히 연구되고 있습니다. 특히 생성적 적대 신경망(GAN)을 활용한 방법들이 좋은 성능을 보이고 있습니다. GAN 모델을 통해 참조 이미지의 스타일을 목표 이미지에 전이시키는 방식입니다. 예를 들어 Aitalian et al. (2019)의 연구에서는 CycleGAN 기반 모델로 위성영상의 색상을 효과적으로 보정했습니다.

3. 실무에서는 아직까지 전통적인 방법과 딥러닝 방법을 혼용하여 사용하는 것으로 알고 있습니다. 전통적 방법으로 1차 보정을 한 후, 딥러닝 모델을 통해 미세 조정을 하는 식입니다.

4. 새로운 연구 과제로 딥러닝 기반 색상 보정 모델을 개발하는 것은 매우 가치가 있다고 봅니다. 딥러닝 모델의 성능이 점점 좋아지고 있고, 실무에서도 활용도가 높아질 것으로 전망됩니다. 다만 데이터 확보와 정답 라벨링이 어려운 점을 감안해야 합니다.

5. 참고할 만한 연구로는 위에서 언급한 Aitalian et al. (2019)의 연구 외에도, Zhang et al. (2019) "Image Style Transfer Using Convolutional Neural Networks", Shendryk et al. (2022) "Cross-Sensor Color Adjustment of Satellite Imagery Using Cycle-Consistent Generative Adversarial Networks" 등이 있습니다.

===========
일반적으로 다음과 같은 방법들이 사용됩니다.

1.1 히스토그램 매칭
간단하고 효율적인 방법
대상 영상의 히스토그램을 분석하고 일관성 있는 대상 히스토그램으로 매칭
명확한 히스토그램 패턴을 가진 영상에 효과적
단순한 방식으로 인해 복잡한 색상 변화를 충분히 반영하지 못할 수 있음

1.2 통계 기반 방법
평균, 분산, 표준 편차 등 통계적 특징을 활용하여 색상 보정
히스토그램 매칭보다 더 유연하고 다양한 색상 변화에 적응 가능
강도 조절, 색상 변환 등 다양한 작업 수행 가능
모델 학습 필요 없이 바로 적용 가능

1.3 딥러닝 기반 방법
신경망 모델을 학습하여 영상의 색상 변화를 자동으로 파악하고 보정
히스토그램 매칭이나 통계 기반 방법보다 더 정교하고 정확한 보정 가능
다양한 유형의 영상에 적용 가능
방대한 양의 학습 데이터 필요

1.4 GAN (Generative Adversarial Networks) 기반 방법
생성자 모델과 판별자 모델을 함께 사용하여 영상의 색상을 현실적인 방식으로 변환
딥러닝 기반 방법보다 더 자연스럽고 사실적인 결과 도출 가능
모델 학습 난이도가 높음

연구 논문
"Cross-Sensor Color Adjustment of Satellite Imagery Using Cycle-Consistent Generative Adversarial Networks" - Shendryk et al. (2022)
CycleGAN 기반 모델로 서로 다른 센서에서 촬영된 위성영상의 색상을 자동으로 보정하는 방법을 제안

"Satellite Image Color Transfer with Semantic Preservations" - Yan et al. (2022)
의미론적 분할 기법과 생성적 모델을 결합하여 참조 영상의 색상 특징을 목표 영상에 전이시키는 기법 제안

"Self-Supervised Consistent Color Transfer for Satellite Imagery" - Li et al. (2021)
자기지도 학습 기반으로 동일 지역의 다중 시기 위성영상 간 색상 불일치를 보정하는 방법 제시

"Automatic Color Augmentation for Satellite Imagery" - Benjdira et al. (2019) - ICCV
위성영상에 대한 자동 색상 증강 기법을 제안한 주목할 만한 논문입니다. CycleGAN 기반 모델을 사용하여 위성영상의 색상을 다양하게 변환할 수 있습니다.

"SMOG-Aware Unsupervised Domain Translation for Remote Sensing Images" - Borji et al. (2021) - CVPR
딥러닝 기반으로 대기 상태 변화에 따른 위성영상 색상 변화를 효과적으로 보상할 수 있는 방법론을 제시했습니다.

"Learning Dense Semantic Correspondences from Cross-Domain Image Pairs without Annotations" - Jeong et al. (2022) - CVPR
어노테이션 없이 서로 다른 도메인의 이미지 쌍에서 의미 있는 대응점들을 학습하는 기법을 제안했습니다. 위성/항공 영상의 색상 통일에 활용 가능합니다.

"Unsupervised Cross-Sensor Color Transfer for Remote Sensing Images" - Tsai et al. (2022) - Remote Sensing
서로 다른 센서에서 촬영된 위성영상 간 비지도 색상 전이 기법을 다루었으며, 정량적 실험을 통해 기존 기법 대비 성능 향상을 보였습니다.