{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "DL04_02_GAN01_BASIC_v10.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Za3wRl2kkb",
        "colab_type": "text"
      },
      "source": [
        "#### colab로 시작하기\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/LDJWJ/00_TOTO_MLDL_CLASS/blob/master/DL04_02_GAN01_BASIC_v10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHnsnFbP2kkm",
        "colab_type": "text"
      },
      "source": [
        "## GAN(Generative Adversarial Networks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zIKU34-2kkv",
        "colab_type": "text"
      },
      "source": [
        "#### 딥러닝의 미래로 불리는 GAN은 **대립(adversarial)하는 두 신경망을 경쟁**시켜가며 결과물을 생성하는 방법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEEW39ug2kk2",
        "colab_type": "text"
      },
      "source": [
        "#### 실제이미지를 구분자(Discriminator)에게 이 이미지가 진짜임을 판단하게 하고, 생성자(Generator)를 통해 노이즈로부터 임의의 이미지를 만들고 이것을 다시 같은 구분자를 통해 진짜 이미지인지를 판단하게 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP0v-3KX2kk-",
        "colab_type": "text"
      },
      "source": [
        "### 응용 예 <br>\n",
        "\n",
        "(가) 고흐 풍 그림으로 그려주기 <br>\n",
        "(나) 선으로 그려진 만화를 자동으로 채색 <br>\n",
        "(다) 모자이크를 없애주기 <br>\n",
        "(라) GAN 기법을 이용한 자연어 문장 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l4WmAqj2klE",
        "colab_type": "text"
      },
      "source": [
        "### 이번시간의 학습 내용\n",
        "* 손글씨 데이터 셋(MNIST)을 이용하여 손글씨를 무작위로 생성하는 예제 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290jAHyq2klI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "24387372-dd37-458a-cb90-1e997e89da10"
      },
      "source": [
        "# 논문링크 : https://arxiv.org/abs/1406.2661\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib as ml\n",
        "\n",
        "print(\"tf : {}, numpy : {}, matplotlib : {}\".format(tf.__version__, \n",
        "                                                   ml.__version__, np.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tf : 1.15.0, numpy : 3.2.0, matplotlib : 1.18.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-8mWO62klY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "52723f09-8f3d-4996-9ad2-619c53ddb50a"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCK-OTp42klq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fde381e5-b084-4230-ecd5-4597918c11a8"
      },
      "source": [
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape)\n",
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(10000, 10)\n",
            "(55000, 784)\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-HclxIe2kl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f650c191-6ccf-48b0-f64a-00b3827a9e60"
      },
      "source": [
        "print(type(mnist.train.images) )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZEM2SJM2kmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7529c30c-e57d-49ac-b8e5-8afe8b995f05"
      },
      "source": [
        "print(mnist.train.labels[0:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQct9NqN2kmq",
        "colab_type": "text"
      },
      "source": [
        "### 01. 기본 옵션 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZnuglu52kmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_epoch = 100       # epoch 수 설정\n",
        "batch_size = 100        # 배치 사이즈\n",
        "learning_rate = 0.0002  # 학습률\n",
        "\n",
        "# 신경망 레이어 구성 옵션\n",
        "n_hidden = 256          # 은닉층 노드\n",
        "n_input = 28 * 28       # 입력 \n",
        "n_noise = 128           # 생성기의 입력값으로 사용할 노이즈의 크기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ckcOkD2km8",
        "colab_type": "text"
      },
      "source": [
        "### 02. 신경망 모델 구성\n",
        " * **노이즈**를 이용하여 데이터 생성\n",
        " * 비지도학습이므로 목표(Y)가 없음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij1e15ee2km_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GAN 도 Unsupervised 학습이므로 Autoencoder 처럼 Y 를 사용하지 않습니다.\n",
        "X = tf.placeholder(tf.float32, [None, n_input])\n",
        "\n",
        "# 노이즈 Z를 입력값으로 사용합니다.\n",
        "Z = tf.placeholder(tf.float32, [None, n_noise])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ9eRQMZ2knS",
        "colab_type": "text"
      },
      "source": [
        "### 생성자 신경망, 판별자 신경망 변수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMKaGK8h2knZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3374480f-a3a1-4b26-a946-60a00e572e80"
      },
      "source": [
        "# 생성자 신경망에 사용하는 변수(Weight, bias)\n",
        "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
        "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
        "\n",
        "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
        "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
        "\n",
        "print(G_W1, G_W2)\n",
        "print(G_b1, G_b2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_8:0' shape=(128, 256) dtype=float32_ref> <tf.Variable 'Variable_10:0' shape=(256, 784) dtype=float32_ref>\n",
            "<tf.Variable 'Variable_9:0' shape=(256,) dtype=float32_ref> <tf.Variable 'Variable_11:0' shape=(784,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qAwOAqS2knm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f6f2847a-0ed6-4fc4-85c1-64babc3f357d"
      },
      "source": [
        "# 판별기 신경망에 사용하는 변수들입니다.\n",
        "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
        "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
        "\n",
        "# 판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라값입니다.\n",
        "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
        "D_b2 = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "print(D_W1, D_W2)\n",
        "print(D_b1, D_b2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_12:0' shape=(784, 256) dtype=float32_ref> <tf.Variable 'Variable_14:0' shape=(256, 1) dtype=float32_ref>\n",
            "<tf.Variable 'Variable_13:0' shape=(256,) dtype=float32_ref> <tf.Variable 'Variable_15:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p89D4OkV2knz",
        "colab_type": "text"
      },
      "source": [
        "### 2-1 생성자(G) 신경망 구성\n",
        " * 무작위 생성한 노이즈를 받아, 가중치와 편향을 반영하여 은닉층 구성.\n",
        " * sigmoid 함수를 이용하여 최종 결과값 0~1 사이의 값 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-zk8RNr2kn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(noise_z):\n",
        "    hidden = tf.nn.relu(\n",
        "                    tf.matmul(noise_z, G_W1) + G_b1)\n",
        "    output = tf.nn.sigmoid(\n",
        "                    tf.matmul(hidden, G_W2) + G_b2)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RshUy_Sv2koD",
        "colab_type": "text"
      },
      "source": [
        "### 2-2 구분자(D) 신경망 구성\n",
        " * 구분자 신경망 구성, 가중치와 편향을 반영한 데이터 출력\n",
        " * sigmoid 함수를 이용하여 최종 결과값 0~1 사이의 값 반환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y9vkHer2koH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator(inputs):\n",
        "    hidden = tf.nn.relu(\n",
        "                    tf.matmul(inputs, D_W1) + D_b1)\n",
        "    output = tf.nn.sigmoid(\n",
        "                    tf.matmul(hidden, D_W2) + D_b2)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-L1Yznx2koY",
        "colab_type": "text"
      },
      "source": [
        "### 2-3 생성자 신경망의 노이즈 발생을 위한 노이즈 생성 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCrJqZRa2koh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 랜덤한 노이즈(Z)를 만듭니다.\n",
        "def get_noise(batch_size, n_noise):\n",
        "    return np.random.normal(size=(batch_size, n_noise))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh1KuHdq2kov",
        "colab_type": "text"
      },
      "source": [
        "### 2-4 신경망 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foVyxnUh2koy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a47420e1-e6ce-47b0-f8fa-456fdc4fc201"
      },
      "source": [
        "# 노이즈를 이용해 랜덤한 이미지를 생성합니다.\n",
        "# Z에는 실행 시, noise가 입력됨.\n",
        "G = generator(Z)\n",
        "print(\"generator :\", G)\n",
        "\n",
        "# 노이즈를 이용해 생성한 이미지(G)가 진짜 이미지인지 판별한 값을 구합니다.\n",
        "D_fake = discriminator(G)\n",
        "print(\"discriminator use Noise Image:\", D_fake)\n",
        "\n",
        "# 진짜 이미지를 이용해(X) 판별한 값을 구합니다.\n",
        "D_real = discriminator(X)\n",
        "print(\"discriminator use Real Image:\", D_real)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generator : Tensor(\"Sigmoid_6:0\", shape=(?, 784), dtype=float32)\n",
            "discriminator use Noise Image: Tensor(\"Sigmoid_7:0\", shape=(?, 1), dtype=float32)\n",
            "discriminator use Real Image: Tensor(\"Sigmoid_8:0\", shape=(?, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0KRKhLp2kpD",
        "colab_type": "text"
      },
      "source": [
        " * GAN은 생성자(Generator) : **구분자가 1로 예측하도록 하는 것을 목표**로 학습시킴. \n",
        " * GAN은 구분자(Discriminator) : **진짜 데이터를 받으면 1**로 **가짜 데이터를 받으면 0으로 예측**하도록 학습시킴."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBeI4nZp2kpG",
        "colab_type": "text"
      },
      "source": [
        "### GAN의 모델의 최적화\n",
        "* 각각의 신경망의 loss_G와 loss_D를 최대화 하는 것. \n",
        "   * 단, 서로의 손실이 연관되어 있어, 두 손실값이 같이 증가가 어려움.\n",
        "* loss_D를 최대화하기 위해서는 D_gene값을 최소화시킴.\n",
        "* 판별기에 진짜 이미지를 넣었을 때에도 최대값을 : tf.log(D_real)\n",
        "* 가짜 이미지를 넣었을 때에도 최대값을 : tf.log(1 - D_gene)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSbO9bQ22kpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1 - D_fake))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZXAwnZs2kpW",
        "colab_type": "text"
      },
      "source": [
        "* loss_G(생성자 손실)를 최대화하기 위해서는 D_gene값을 최대화 한다.\n",
        "* 가짜 이미지를 넣었을 때, 판별기가 최대한 실제 이미지라고 판단하도록 생성기 신경망을 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQYIekz62kpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 결국 D_gene 값을 최대화하는 것이므로 다음과 같이 사용할 수 있습니다.\n",
        "loss_G = tf.reduce_mean(tf.log(D_fake))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j4qR1kq2kpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_D 를 구할 때는 판별기 신경망에 사용되는 변수만 사용하고,\n",
        "# loss_G 를 구할 때는 생성기 신경망에 사용되는 변수만 사용하여 최적화를 합니다.\n",
        "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
        "G_var_list = [G_W1, G_b1, G_W2, G_b2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMAsOUpR2kp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "25bb0561-d2b4-44bf-f1fe-c74d54fd9600"
      },
      "source": [
        "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
        "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
        "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,\n",
        "                                                         var_list=D_var_list)\n",
        "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,\n",
        "                                                         var_list=G_var_list)\n",
        "\n",
        "print(train_D)\n",
        "print(train_G)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: \"Adam_4\"\n",
            "op: \"NoOp\"\n",
            "input: \"^Adam_4/update_Variable_12/ApplyAdam\"\n",
            "input: \"^Adam_4/update_Variable_13/ApplyAdam\"\n",
            "input: \"^Adam_4/update_Variable_14/ApplyAdam\"\n",
            "input: \"^Adam_4/update_Variable_15/ApplyAdam\"\n",
            "input: \"^Adam_4/Assign\"\n",
            "input: \"^Adam_4/Assign_1\"\n",
            "\n",
            "name: \"Adam_5\"\n",
            "op: \"NoOp\"\n",
            "input: \"^Adam_5/update_Variable_8/ApplyAdam\"\n",
            "input: \"^Adam_5/update_Variable_9/ApplyAdam\"\n",
            "input: \"^Adam_5/update_Variable_10/ApplyAdam\"\n",
            "input: \"^Adam_5/update_Variable_11/ApplyAdam\"\n",
            "input: \"^Adam_5/Assign\"\n",
            "input: \"^Adam_5/Assign_1\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3kMTD5T2kqH",
        "colab_type": "text"
      },
      "source": [
        "### 03. 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFq6kiPV2kqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "total_batch = int(mnist.train.num_examples/batch_size)\n",
        "loss_val_D, loss_val_G = 0, 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdaKmYmi2kqY",
        "colab_type": "text"
      },
      "source": [
        "* 학습 후, 학습되는 이미지 저장을 위해 실행되는 위치에 '/samples'라는 디렉터리(폴더) 생성이 필요함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wP6ZuyZ72kqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f6542b3-6c64-4dec-e303-c5dc487e62ac"
      },
      "source": [
        "%%time\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        noise = get_noise(batch_size, n_noise)\n",
        "\n",
        "        # 판별기와 생성기 신경망을 각각 학습시킵니다.\n",
        "        _, loss_val_D = sess.run([train_D, loss_D],\n",
        "                                 feed_dict={X: batch_xs, Z: noise})\n",
        "        _, loss_val_G = sess.run([train_G, loss_G],\n",
        "                                 feed_dict={Z: noise})\n",
        "\n",
        "    print('Epoch:', '%04d' % epoch,\n",
        "          'D loss: {:.4}'.format(loss_val_D),\n",
        "          'G loss: {:.4}'.format(loss_val_G))\n",
        "                                 \n",
        "    #########\n",
        "    # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
        "    ######\n",
        "    if epoch == 0 or (epoch + 1) % 10 == 0:\n",
        "        sample_size = 10\n",
        "        noise = get_noise(sample_size, n_noise)\n",
        "        samples = sess.run(G, feed_dict={Z: noise})\n",
        "\n",
        "        fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))\n",
        "\n",
        "        for i in range(sample_size):\n",
        "            ax[i].set_axis_off()\n",
        "            ax[i].imshow(np.reshape(samples[i], (28, 28)))\n",
        "\n",
        "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "print('최적화 완료!')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0000 D loss: -0.3424 G loss: -2.474\n",
            "Epoch: 0001 D loss: -0.5758 G loss: -1.487\n",
            "Epoch: 0002 D loss: -0.4218 G loss: -2.174\n",
            "Epoch: 0003 D loss: -0.2815 G loss: -2.554\n",
            "Epoch: 0004 D loss: -0.1707 G loss: -3.076\n",
            "Epoch: 0005 D loss: -0.2009 G loss: -2.881\n",
            "Epoch: 0006 D loss: -0.2332 G loss: -2.837\n",
            "Epoch: 0007 D loss: -0.3761 G loss: -2.898\n",
            "Epoch: 0008 D loss: -0.3448 G loss: -2.522\n",
            "Epoch: 0009 D loss: -0.305 G loss: -2.506\n",
            "Epoch: 0010 D loss: -0.2265 G loss: -2.8\n",
            "Epoch: 0011 D loss: -0.255 G loss: -2.932\n",
            "Epoch: 0012 D loss: -0.259 G loss: -2.655\n",
            "Epoch: 0013 D loss: -0.3811 G loss: -2.441\n",
            "Epoch: 0014 D loss: -0.3041 G loss: -2.572\n",
            "Epoch: 0015 D loss: -0.3438 G loss: -2.773\n",
            "Epoch: 0016 D loss: -0.2022 G loss: -3.198\n",
            "Epoch: 0017 D loss: -0.3514 G loss: -2.964\n",
            "Epoch: 0018 D loss: -0.2345 G loss: -2.82\n",
            "Epoch: 0019 D loss: -0.3612 G loss: -2.974\n",
            "Epoch: 0020 D loss: -0.3152 G loss: -3.097\n",
            "Epoch: 0021 D loss: -0.3702 G loss: -2.721\n",
            "Epoch: 0022 D loss: -0.3934 G loss: -2.82\n",
            "Epoch: 0023 D loss: -0.3523 G loss: -2.788\n",
            "Epoch: 0024 D loss: -0.4415 G loss: -2.599\n",
            "Epoch: 0025 D loss: -0.4088 G loss: -2.914\n",
            "Epoch: 0026 D loss: -0.3567 G loss: -2.964\n",
            "Epoch: 0027 D loss: -0.5355 G loss: -2.806\n",
            "Epoch: 0028 D loss: -0.5096 G loss: -2.703\n",
            "Epoch: 0029 D loss: -0.4162 G loss: -2.514\n",
            "Epoch: 0030 D loss: -0.3192 G loss: -3.069\n",
            "Epoch: 0031 D loss: -0.3253 G loss: -2.979\n",
            "Epoch: 0032 D loss: -0.4464 G loss: -3.18\n",
            "Epoch: 0033 D loss: -0.466 G loss: -2.914\n",
            "Epoch: 0034 D loss: -0.5518 G loss: -2.728\n",
            "Epoch: 0035 D loss: -0.46 G loss: -2.655\n",
            "Epoch: 0036 D loss: -0.2972 G loss: -3.125\n",
            "Epoch: 0037 D loss: -0.509 G loss: -2.72\n",
            "Epoch: 0038 D loss: -0.5126 G loss: -2.44\n",
            "Epoch: 0039 D loss: -0.5282 G loss: -2.726\n",
            "Epoch: 0040 D loss: -0.5623 G loss: -2.869\n",
            "Epoch: 0041 D loss: -0.5146 G loss: -2.394\n",
            "Epoch: 0042 D loss: -0.5788 G loss: -2.337\n",
            "Epoch: 0043 D loss: -0.7198 G loss: -2.462\n",
            "Epoch: 0044 D loss: -0.4661 G loss: -2.302\n",
            "Epoch: 0045 D loss: -0.6133 G loss: -2.375\n",
            "Epoch: 0046 D loss: -0.684 G loss: -2.308\n",
            "Epoch: 0047 D loss: -0.4972 G loss: -2.861\n",
            "Epoch: 0048 D loss: -0.5053 G loss: -2.807\n",
            "Epoch: 0049 D loss: -0.5396 G loss: -2.704\n",
            "Epoch: 0050 D loss: -0.7335 G loss: -2.25\n",
            "Epoch: 0051 D loss: -0.6854 G loss: -1.995\n",
            "Epoch: 0052 D loss: -0.587 G loss: -2.196\n",
            "Epoch: 0053 D loss: -0.743 G loss: -2.213\n",
            "Epoch: 0054 D loss: -0.7722 G loss: -2.171\n",
            "Epoch: 0055 D loss: -0.835 G loss: -2.158\n",
            "Epoch: 0056 D loss: -0.6014 G loss: -2.122\n",
            "Epoch: 0057 D loss: -0.5244 G loss: -2.122\n",
            "Epoch: 0058 D loss: -0.7233 G loss: -2.111\n",
            "Epoch: 0059 D loss: -0.5277 G loss: -2.283\n",
            "Epoch: 0060 D loss: -0.5899 G loss: -2.139\n",
            "Epoch: 0061 D loss: -0.6432 G loss: -2.341\n",
            "Epoch: 0062 D loss: -0.6371 G loss: -2.266\n",
            "Epoch: 0063 D loss: -0.5464 G loss: -2.232\n",
            "Epoch: 0064 D loss: -0.7328 G loss: -1.835\n",
            "Epoch: 0065 D loss: -0.6696 G loss: -2.132\n",
            "Epoch: 0066 D loss: -0.565 G loss: -2.188\n",
            "Epoch: 0067 D loss: -0.6733 G loss: -2.111\n",
            "Epoch: 0068 D loss: -0.7534 G loss: -1.92\n",
            "Epoch: 0069 D loss: -0.5504 G loss: -2.415\n",
            "Epoch: 0070 D loss: -0.5933 G loss: -2.205\n",
            "Epoch: 0071 D loss: -0.6967 G loss: -1.987\n",
            "Epoch: 0072 D loss: -0.6477 G loss: -2.175\n",
            "Epoch: 0073 D loss: -0.7386 G loss: -2.222\n",
            "Epoch: 0074 D loss: -0.8307 G loss: -1.878\n",
            "Epoch: 0075 D loss: -0.7457 G loss: -2.186\n",
            "Epoch: 0076 D loss: -0.6022 G loss: -2.313\n",
            "Epoch: 0078 D loss: -0.65 G loss: -2.145\n",
            "Epoch: 0079 D loss: -0.6686 G loss: -2.173\n",
            "Epoch: 0080 D loss: -0.644 G loss: -2.211\n",
            "Epoch: 0081 D loss: -0.6635 G loss: -2.198\n",
            "Epoch: 0082 D loss: -0.5089 G loss: -2.332\n",
            "Epoch: 0083 D loss: -0.5805 G loss: -2.331\n",
            "Epoch: 0084 D loss: -0.6556 G loss: -2.369\n",
            "Epoch: 0085 D loss: -0.6512 G loss: -2.053\n",
            "Epoch: 0087 D loss: -0.5607 G loss: -1.924\n",
            "Epoch: 0088 D loss: -0.6004 G loss: -2.065\n",
            "Epoch: 0089 D loss: -0.5689 G loss: -2.254\n",
            "Epoch: 0090 D loss: -0.5589 G loss: -2.161\n",
            "Epoch: 0091 D loss: -0.7226 G loss: -2.182\n",
            "Epoch: 0092 D loss: -0.7151 G loss: -2.017\n",
            "Epoch: 0093 D loss: -0.5916 G loss: -2.271\n",
            "Epoch: 0094 D loss: -0.5348 G loss: -2.367\n",
            "Epoch: 0095 D loss: -0.4979 G loss: -2.321\n",
            "Epoch: 0096 D loss: -0.6011 G loss: -2.24\n",
            "Epoch: 0097 D loss: -0.5523 G loss: -2.162\n",
            "Epoch: 0098 D loss: -0.6485 G loss: -2.225\n",
            "Epoch: 0099 D loss: -0.6451 G loss: -2.142\n",
            "최적화 완료!\n",
            "CPU times: user 20min 35s, sys: 57.5 s, total: 21min 32s\n",
            "Wall time: 12min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ77hAo62kqr",
        "colab_type": "text"
      },
      "source": [
        "### REF \n",
        "* GAN에 대한 논문 : https://arxiv.org/abs/1406.2661"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahcwrorz2kqw",
        "colab_type": "text"
      },
      "source": [
        "Copyright 2020 LIM Co.(예영Edu Co.) all rights reserved. <br>\n",
        "교육용으로 작성된 것으로 배포 및 복제시에 사전 허가가 필요합니다. <br>"
      ]
    }
  ]
}